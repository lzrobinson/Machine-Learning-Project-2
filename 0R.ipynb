{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8792e3c7-12f6-4a66-b032-049c5b8e0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR Baseline Model for Book Rating\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import scipy\n",
    "# OVERALL APPROACH:\n",
    "# 1. Read csv file into pandas df\n",
    "# 2. Group by class label\n",
    "# 3. Calculate prior probabilities and likelihood pdfs\n",
    "# 4. Create predict() function for using these pdfs to predict class labels\n",
    "# 6. evaluate() performance by comparing model outputs to ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "18bdcd07-565a-4783-ac28-76000fe9bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    # process csv file into pandas dataframe\n",
    "    df = pd.read_csv(filename)\n",
    "    #df = df.iloc[:, 1:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2850692c-b1ff-4cdd-8bff-014a39bda068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of all the labels\n",
    "def calc_prior(data):\n",
    "    prior_prob = {}\n",
    "\n",
    "    labels = data.values[:, -1]\n",
    "    n = len(labels)\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    for i in range(len(unique_labels)):\n",
    "        prior_prob[unique_labels[i]] = (counts[i] / n).round(2)\n",
    "\n",
    "    return prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32282b91-4a98-4732-8f5a-569a00ce58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Training' for 0R baseline: finds the class with the highest frequency\n",
    "def zero_r_training(df):\n",
    "    priors = calc_prior(df)\n",
    "    maxlabel = list(priors.keys())[0]\n",
    "    maxval = 0\n",
    "    for label in priors.keys():\n",
    "        label_count = 0\n",
    "        for row in df.iterrows():\n",
    "            if row[-1][-1] == label:\n",
    "                label_count += 1\n",
    "        if label_count > maxval:\n",
    "            maxval = label_count\n",
    "            maxlabel = label\n",
    "    return priors, maxlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9be3f43-8932-4abc-af78-660f307092ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero R prediction for test df\n",
    "def zero_r_predict(zero_r_val, test_df):\n",
    "    length = len(test_df)\n",
    "    return pd.Series([zero_r_val]*length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87606f2d-c8d7-4780-b0c0-f2465e5abb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4.0\n",
       "1       4.0\n",
       "2       4.0\n",
       "3       4.0\n",
       "4       4.0\n",
       "       ... \n",
       "5761    4.0\n",
       "5762    4.0\n",
       "5763    4.0\n",
       "5764    4.0\n",
       "5765    4.0\n",
       "Length: 5766, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, preprocess train and test data\n",
    "train_df = preprocess(\"project_data_files/book_rating_train.csv\")\n",
    "test_df = preprocess(\"project_data_files/book_rating_test.csv\")\n",
    "\n",
    "# Train 0R model\n",
    "priors, label = zero_r_training(train_df)\n",
    "\n",
    "# Predict 0R model on test df\n",
    "predictions = zero_r_predict(label, test_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de097905-e4a6-4aee-825d-cc4473078f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pickle.load(open(\"project_data_files/book_text_features_countvec/train_authors_countvectorizer.pkl\", \"rb\"))\n",
    "\n",
    "vocab_dict = vocab.vocabulary_\n",
    "\n",
    "thing = pickle.load(open(\"project_data_files/book_text_features_countvec/train_desc_countvectorizer.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6decbf0-19d9-4560-83fb-df4e389a6086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23063x20766 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 99477 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.load_npz('project_data_files/book_text_features_countvec/train_name_vec.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cc830e4-62e6-4ceb-9391-9b2dd4a145c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052262</td>\n",
       "      <td>-0.263308</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.128574</td>\n",
       "      <td>-0.161565</td>\n",
       "      <td>-0.127520</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>-0.074043</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172811</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>-0.062941</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>-0.065377</td>\n",
       "      <td>0.227973</td>\n",
       "      <td>0.218879</td>\n",
       "      <td>-0.151266</td>\n",
       "      <td>-0.048105</td>\n",
       "      <td>0.300822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.129112</td>\n",
       "      <td>0.021312</td>\n",
       "      <td>0.159166</td>\n",
       "      <td>-0.072448</td>\n",
       "      <td>0.036028</td>\n",
       "      <td>-0.093721</td>\n",
       "      <td>0.129199</td>\n",
       "      <td>0.069736</td>\n",
       "      <td>-0.253263</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245650</td>\n",
       "      <td>-0.049657</td>\n",
       "      <td>0.072740</td>\n",
       "      <td>-0.055925</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.067133</td>\n",
       "      <td>-0.238091</td>\n",
       "      <td>0.109774</td>\n",
       "      <td>-0.156772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.170058</td>\n",
       "      <td>0.052351</td>\n",
       "      <td>-0.013406</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.083173</td>\n",
       "      <td>-0.161439</td>\n",
       "      <td>0.048635</td>\n",
       "      <td>0.089419</td>\n",
       "      <td>-0.072266</td>\n",
       "      <td>-0.063164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033781</td>\n",
       "      <td>0.093943</td>\n",
       "      <td>0.132654</td>\n",
       "      <td>0.030295</td>\n",
       "      <td>0.102714</td>\n",
       "      <td>0.154334</td>\n",
       "      <td>0.129325</td>\n",
       "      <td>-0.231493</td>\n",
       "      <td>0.007541</td>\n",
       "      <td>-0.098540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250849</td>\n",
       "      <td>0.021555</td>\n",
       "      <td>0.091047</td>\n",
       "      <td>-0.041589</td>\n",
       "      <td>-0.040949</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.415056</td>\n",
       "      <td>0.027029</td>\n",
       "      <td>-0.172413</td>\n",
       "      <td>-0.135485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020762</td>\n",
       "      <td>-0.149720</td>\n",
       "      <td>0.150557</td>\n",
       "      <td>0.294355</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.285179</td>\n",
       "      <td>0.049340</td>\n",
       "      <td>-0.037548</td>\n",
       "      <td>0.042920</td>\n",
       "      <td>0.176173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.041681</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>-0.051164</td>\n",
       "      <td>-0.076813</td>\n",
       "      <td>0.096855</td>\n",
       "      <td>-0.215943</td>\n",
       "      <td>0.152729</td>\n",
       "      <td>0.267636</td>\n",
       "      <td>-0.079954</td>\n",
       "      <td>-0.065560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191644</td>\n",
       "      <td>0.044182</td>\n",
       "      <td>0.054631</td>\n",
       "      <td>-0.025782</td>\n",
       "      <td>0.049917</td>\n",
       "      <td>0.122052</td>\n",
       "      <td>-0.084216</td>\n",
       "      <td>-0.096424</td>\n",
       "      <td>-0.068681</td>\n",
       "      <td>-0.005293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>-0.129420</td>\n",
       "      <td>0.130302</td>\n",
       "      <td>-0.037361</td>\n",
       "      <td>-0.004281</td>\n",
       "      <td>-0.255112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>-0.062899</td>\n",
       "      <td>0.048064</td>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.191065</td>\n",
       "      <td>0.096081</td>\n",
       "      <td>-0.100516</td>\n",
       "      <td>-0.190299</td>\n",
       "      <td>0.224559</td>\n",
       "      <td>0.086601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23059</th>\n",
       "      <td>-0.024484</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.015977</td>\n",
       "      <td>0.086630</td>\n",
       "      <td>0.082127</td>\n",
       "      <td>-0.174537</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.111608</td>\n",
       "      <td>-0.106961</td>\n",
       "      <td>-0.147956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150964</td>\n",
       "      <td>-0.029046</td>\n",
       "      <td>0.171029</td>\n",
       "      <td>-0.072123</td>\n",
       "      <td>-0.004459</td>\n",
       "      <td>0.247430</td>\n",
       "      <td>0.111973</td>\n",
       "      <td>0.019573</td>\n",
       "      <td>0.070569</td>\n",
       "      <td>-0.112066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23060</th>\n",
       "      <td>-0.099309</td>\n",
       "      <td>-0.046230</td>\n",
       "      <td>-0.033294</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>-0.055477</td>\n",
       "      <td>-0.033886</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>-0.126636</td>\n",
       "      <td>0.127742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193755</td>\n",
       "      <td>-0.118570</td>\n",
       "      <td>0.006740</td>\n",
       "      <td>-0.108623</td>\n",
       "      <td>-0.036143</td>\n",
       "      <td>0.168113</td>\n",
       "      <td>0.136478</td>\n",
       "      <td>0.087885</td>\n",
       "      <td>0.113180</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23061</th>\n",
       "      <td>-0.038388</td>\n",
       "      <td>0.065679</td>\n",
       "      <td>-0.159324</td>\n",
       "      <td>-0.048682</td>\n",
       "      <td>0.054175</td>\n",
       "      <td>0.317751</td>\n",
       "      <td>0.065931</td>\n",
       "      <td>-0.126021</td>\n",
       "      <td>-0.105057</td>\n",
       "      <td>-0.147185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.154127</td>\n",
       "      <td>0.219128</td>\n",
       "      <td>-0.305824</td>\n",
       "      <td>-0.017904</td>\n",
       "      <td>-0.059886</td>\n",
       "      <td>0.108616</td>\n",
       "      <td>0.041879</td>\n",
       "      <td>-0.138893</td>\n",
       "      <td>-0.044187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23062</th>\n",
       "      <td>-0.051934</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>0.030417</td>\n",
       "      <td>0.044278</td>\n",
       "      <td>-0.031339</td>\n",
       "      <td>-0.020412</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.073363</td>\n",
       "      <td>-0.068429</td>\n",
       "      <td>-0.037205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068714</td>\n",
       "      <td>-0.065924</td>\n",
       "      <td>0.082228</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.099006</td>\n",
       "      <td>0.081608</td>\n",
       "      <td>0.094459</td>\n",
       "      <td>-0.048776</td>\n",
       "      <td>0.032433</td>\n",
       "      <td>0.132977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23063 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0      0.052262 -0.263308  0.026872  0.128574 -0.161565 -0.127520  0.249588   \n",
       "1     -0.129112  0.021312  0.159166 -0.072448  0.036028 -0.093721  0.129199   \n",
       "2     -0.170058  0.052351 -0.013406  0.099001  0.083173 -0.161439  0.048635   \n",
       "3      0.250849  0.021555  0.091047 -0.041589 -0.040949  0.240260  0.415056   \n",
       "4     -0.041681  0.038051 -0.051164 -0.076813  0.096855 -0.215943  0.152729   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23058  0.007497  0.000220  0.019723 -0.003321  0.021097 -0.129420  0.130302   \n",
       "23059 -0.024484  0.000467 -0.015977  0.086630  0.082127 -0.174537  0.011694   \n",
       "23060 -0.099309 -0.046230 -0.033294  0.242591 -0.055477 -0.033886  0.026869   \n",
       "23061 -0.038388  0.065679 -0.159324 -0.048682  0.054175  0.317751  0.065931   \n",
       "23062 -0.051934 -0.005339  0.030417  0.044278 -0.031339 -0.020412  0.038031   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "0      0.037621 -0.074043  0.072854  ... -0.172811  0.098389 -0.062941   \n",
       "1      0.069736 -0.253263 -0.066424  ...  0.245650 -0.049657  0.072740   \n",
       "2      0.089419 -0.072266 -0.063164  ... -0.033781  0.093943  0.132654   \n",
       "3      0.027029 -0.172413 -0.135485  ...  0.020762 -0.149720  0.150557   \n",
       "4      0.267636 -0.079954 -0.065560  ...  0.191644  0.044182  0.054631   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "23058 -0.037361 -0.004281 -0.255112  ... -0.000418 -0.062899  0.048064   \n",
       "23059  0.111608 -0.106961 -0.147956  ...  0.150964 -0.029046  0.171029   \n",
       "23060  0.038410 -0.126636  0.127742  ...  0.193755 -0.118570  0.006740   \n",
       "23061 -0.126021 -0.105057 -0.147185  ...  0.009007  0.154127  0.219128   \n",
       "23062  0.073363 -0.068429 -0.037205  ...  0.068714 -0.065924  0.082228   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "0      0.118057 -0.065377  0.227973  0.218879 -0.151266 -0.048105  0.300822  \n",
       "1     -0.055925 -0.000046  0.140500  0.067133 -0.238091  0.109774 -0.156772  \n",
       "2      0.030295  0.102714  0.154334  0.129325 -0.231493  0.007541 -0.098540  \n",
       "3      0.294355  0.001157  0.285179  0.049340 -0.037548  0.042920  0.176173  \n",
       "4     -0.025782  0.049917  0.122052 -0.084216 -0.096424 -0.068681 -0.005293  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "23058  0.029612  0.191065  0.096081 -0.100516 -0.190299  0.224559  0.086601  \n",
       "23059 -0.072123 -0.004459  0.247430  0.111973  0.019573  0.070569 -0.112066  \n",
       "23060 -0.108623 -0.036143  0.168113  0.136478  0.087885  0.113180  0.000569  \n",
       "23061 -0.305824 -0.017904 -0.059886  0.108616  0.041879 -0.138893 -0.044187  \n",
       "23062 -0.003849  0.099006  0.081608  0.094459 -0.048776  0.032433  0.132977  \n",
       "\n",
       "[23063 rows x 100 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(r\"project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8f2cf4-af2a-4bba-a63c-483a1213bce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
