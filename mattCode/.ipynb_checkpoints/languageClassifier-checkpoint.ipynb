{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b42a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from operator import truediv\n",
    "\n",
    "\n",
    "'''Seems to be a good model, has good counts, verified a few instances seems to perform great in fact'''\n",
    "def learnLanguage(file, doc2vec):\n",
    "    \n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    X = pd.read_csv(doc2vec, index_col = False, delimiter = ',', header = None)\n",
    "    y = data[\"Language\"]\n",
    "    \n",
    "    y = pd.Series(y)\n",
    "    # Assuming you have a feature matrix `X` and a target variable `y`\n",
    "    # X should contain other features like doc2vec and word frequency counts\n",
    "    # y should contain the language labels (with missing values)\n",
    "\n",
    "    # Split the dataset into instances with and without missing language values\n",
    "    X_with_language = X[~y.isnull()]\n",
    "    y_with_language = y[~y.isnull()]\n",
    "    X_missing_language = X[y.isnull()]\n",
    "\n",
    "    # Split the dataset with language into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_with_language, y_with_language, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a Random Forest classifier on the instances with language\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the missing language values using the trained model\n",
    "    imputed_language = rf.predict(X_missing_language)\n",
    "    \n",
    "    # Also performance on test data\n",
    "    y_pred = rf.predict(X_test)\n",
    "    confusion_matrix_plot(y_pred, y_test)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Merge the imputed language values with the original dataset\n",
    "    y[y.isnull()] = imputed_language\n",
    "\n",
    "    # Now you can proceed with your machine learning algorithm using the complete dataset\n",
    "    return y\n",
    "\n",
    "#lol = learnLanguage(\"Data/book_rating_train.csv\", \"Data/book_text_features_doc2vec/train_desc_doc2vec100.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfd80537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################distance and similarity measures used ################\n",
    "\n",
    "def cosine_sim(v1, v2):\n",
    "    #note v1 and v2 are pandas series of equal length\n",
    "    \n",
    "    i = 0\n",
    "    dotProduct = 0\n",
    "    absV1 = 0\n",
    "    absV2 = 0\n",
    "    \n",
    "    while i < len(v1):\n",
    "        dotProduct += v1[i]*v2[i]\n",
    "        absV1 += v1[i]**2\n",
    "        absV2 += v2[i]**2\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "    absV1 = np.sqrt(absV1)\n",
    "    absV2 = np.sqrt(absV2)\n",
    "    return dotProduct / (absV1 * absV2)\n",
    "\n",
    "def manDistance(v1, v2):\n",
    "    \n",
    "    i = 0\n",
    "    totalDistance = 0\n",
    "    while i < len(v1):\n",
    "        totalDistance = np.abs(v1[i] - v2[i])\n",
    "        i += 1\n",
    "        \n",
    "    return totalDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75619216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for finding the best language class, first is more robust\n",
    "\n",
    "def langClass(centroids, row, mode = \"cosine\"):\n",
    "    \n",
    "    simScores = {}\n",
    "    print(row.name)\n",
    "    for centroid in centroids:\n",
    "        if mode == \"cosine\":\n",
    "            simScores[centroid.name] = cosine_sim(centroid, row)\n",
    "        else:\n",
    "            simScores[centroid.name] = manDistance(centroid, row)\n",
    "        \n",
    "    #setting eng as base lang\n",
    "    maxSim = simScores[\"fre\"]\n",
    "    bestLang = \"fre\"\n",
    "    for lang, sim in simScores.items():\n",
    "        \n",
    "        #print(f\"lang is {lang}, sim is {sim}\")\n",
    "        \n",
    "        if mode == \"cosine\":\n",
    "            if sim > maxSim:\n",
    "                maxSim = sim\n",
    "                bestLang = lang\n",
    "                \n",
    "        else:\n",
    "            if sim < maxSim:\n",
    "                maxSim = sim\n",
    "                bestLang = lang\n",
    "    return bestLang\n",
    "\n",
    "\n",
    "def langClass2(centroids, row):\n",
    "    \n",
    "    simScores = {}\n",
    "    for centroid in centroids:\n",
    "         simScores[centroid.name] = manDistance(centroid, row)\n",
    "        \n",
    "    #setting eng as base lang\n",
    "    maxSim = simScores[\"fre\"]\n",
    "    bestLang = \"fre\"\n",
    "    for lang, sim in simScores.items():\n",
    "        \n",
    "        #print(f\"lang is {lang}, sim is {sim}\")\n",
    "    \n",
    "        if sim < maxSim:\n",
    "            maxSim = sim\n",
    "            bestLang = lang\n",
    "            \n",
    "    return bestLang\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "217dbc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Counts with Cosine Similarity\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'manDistClass' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage Counts with Cosine Similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmanDistClass\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLanguage Counts with Manhattan Distance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(manDist2Class[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'manDistClass' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Language Counts with Cosine Similarity\")\n",
    "print(manDistClass[\"Language\"].value_counts())\n",
    "\n",
    "print(\"\\nLanguage Counts with Manhattan Distance\")\n",
    "\n",
    "print(manDist2Class[\"Language\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0eaf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from operator import truediv\n",
    "\n",
    "\n",
    "'''Seems to be a good model, has good counts, verified a few instances seems to perform great in fact'''\n",
    "def learnLanguage(file, doc2vec):\n",
    "    \n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    X = pd.read_csv(doc2vec, index_col = False, delimiter = ',', header = None)\n",
    "    y = data[\"Language\"]\n",
    "    \n",
    "    y = pd.Series(y)\n",
    "    # Assuming you have a feature matrix `X` and a target variable `y`\n",
    "    # X should contain other features like doc2vec and word frequency counts\n",
    "    # y should contain the language labels (with missing values)\n",
    "\n",
    "    # Split the dataset into instances with and without missing language values\n",
    "    X_with_language = X[~y.isnull()]\n",
    "    y_with_language = y[~y.isnull()]\n",
    "    X_missing_language = X[y.isnull()]\n",
    "\n",
    "    # Split the dataset with language into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_with_language, y_with_language, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a Random Forest classifier on the instances with language\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the missing language values using the trained model\n",
    "    imputed_language = rf.predict(X_missing_language)\n",
    "    \n",
    "    # Also performance on test data\n",
    "    y_pred = rf.predict(X_test)\n",
    "    confusion_matrix_plot(y_pred, y_test)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Merge the imputed language values with the original dataset\n",
    "    y[y.isnull()] = imputed_language\n",
    "\n",
    "    # Now you can proceed with your machine learning algorithm using the complete dataset\n",
    "    return y\n",
    "\n",
    "#lol = learnLanguage(\"Data/book_rating_train.csv\", \"Data/book_text_features_doc2vec/train_desc_doc2vec100.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d937c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lol \u001b[38;5;241m=\u001b[39m \u001b[43mlearnLanguage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/book_rating_test.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/book_text_features_doc2vec/test_desc_doc2vec100.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage counts with Random-Forest classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(lol\u001b[38;5;241m.\u001b[39mvalue_counts())\n",
      "Cell \u001b[1;32mIn[1], line 42\u001b[0m, in \u001b[0;36mlearnLanguage\u001b[1;34m(file, doc2vec)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Also performance on test data\u001b[39;00m\n\u001b[0;32m     41\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m---> 42\u001b[0m \u001b[43mconfusion_matrix_plot\u001b[49m(y_pred, y_test)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Merge the imputed language values with the original dataset\u001b[39;00m\n\u001b[0;32m     47\u001b[0m y[y\u001b[38;5;241m.\u001b[39misnull()] \u001b[38;5;241m=\u001b[39m imputed_language\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix_plot' is not defined"
     ]
    }
   ],
   "source": [
    "lol = learnLanguage(\"Data/book_rating_test.csv\", \"Data/book_text_features_doc2vec/test_desc_doc2vec100.csv\")\n",
    "print(\"Language counts with Random-Forest classifier\")\n",
    "print(lol.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50988496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None,\n",
    "#                       'display.max_columns', None,\n",
    "#                       'display.precision', 3,\n",
    "#                       ):\n",
    "#    display(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f958a952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y_pred, ys):\n",
    "    \n",
    "    labels = ys.unique()\n",
    "    print(labels)\n",
    "    \n",
    "    cm = confusion_matrix(ys, y_pred, labels = labels)\n",
    "    \n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    evalMetrics = classification_report(ys, y_pred, digits=3)\n",
    "    print(evalMetrics)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64661de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Language classifier random forest implementation made adapted heavily from code generated from the AI tool, ChatGPT'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
