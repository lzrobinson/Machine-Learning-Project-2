{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b7fc2c4-705e-4170-8549-00fd78deac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a1b785-4b31-4c9c-b7dc-fb37b935c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_csv(file_path):\n",
    "    # Read the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Handling missing values\n",
    "    # Replace any missing values (NaN) with appropriate strategies\n",
    "    # For numerical columns, you can use methods like mean, median, or interpolation\n",
    "    df.fillna(df.mean(), inplace=True)  # Example: Replace missing values with column means\n",
    "    \n",
    "    # For categorical columns, you can use methods like mode or a constant value\n",
    "    df.fillna('Unknown', inplace=True)  # Example: Replace missing values with 'Unknown'\n",
    "    \n",
    "    # Process or remodel the description columns\n",
    "    # Depending on your specific use case, you can apply techniques like text preprocessing, feature extraction, or encoding\n",
    "    \n",
    "    # Text preprocessing: Remove special characters, convert to lowercase, etc.\n",
    "    #df['description'] = df['description'].str.replace('[^\\w\\s]', '').str.lower()\n",
    "    \n",
    "    # Feature extraction: Extract relevant information from the description\n",
    "    # You can use techniques like TF-IDF, word embeddings, or topic modeling to extract features\n",
    "    \n",
    "    # Encoding: Convert categorical description columns into numeric representations\n",
    "    # Techniques like one-hot encoding or word embeddings can be useful\n",
    "    \n",
    "    # Return the preprocessed dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50557e2f-a788-4217-b957-e16067a3ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, test_size):\n",
    "    # Separate the features and target variable\n",
    "    X = df.drop('target', axis=1)\n",
    "    y = df['target']\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Return the split datasets\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "316a35f4-9420-4c20-b66c-b39295cf50de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(test_df, results_series):\n",
    "    successful_count = 0\n",
    "    for test, result in zip(test_df.iterrows(), results_series.iteritems()):\n",
    "        if test[-1][-1] == result[1]:\n",
    "            successful_count += 1\n",
    "    if (len(test_df) != 0):\n",
    "        return successful_count / (len(test_df))\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc38ca34-719c-41f6-999b-9c17b92bbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision(test_df, results_series, positive_label):\n",
    "    tp_count = 0\n",
    "    fp_count = 0\n",
    "    for test, result in zip(test_df.iterrows(), results_series.iteritems()):\n",
    "        if result[1] == positive_label:\n",
    "            if test[-1][-1] == result[1]:\n",
    "                tp_count += 1\n",
    "            else:\n",
    "                fp_count += 1\n",
    "    if (tp_count + fp_count != 0):\n",
    "        return tp_count / (tp_count + fp_count)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afeb30db-1891-43c6-ab27-889c35eb8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(test_df, results_series, positive_label):\n",
    "    tp_count = 0\n",
    "    fn_count = 0\n",
    "    for test, result in zip(test_df.iterrows(), results_series.iteritems()):\n",
    "        if test[-1][-1] == positive_label:\n",
    "            if test[-1][-1] == result[1]:\n",
    "                tp_count += 1\n",
    "            else:\n",
    "                fn_count += 1\n",
    "    if (tp_count + fn_count != 0):\n",
    "        return tp_count / (tp_count + fn_count)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5fcab34-fcf1-4d99-bf85-d9b67e83741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_letter_to_cols(df, letter):\n",
    "    for column in df.columns:\n",
    "        new_name = letter + str(column)\n",
    "        df.rename(columns={column: new_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b3bea6d-ab50-422c-a4d7-46925fd7a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leoro\\AppData\\Local\\Temp\\ipykernel_17316\\2049216653.py:8: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.fillna(df.mean(), inplace=True)  # Example: Replace missing values with column means\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_csv('project_data_files/book_rating_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92cb17ef-b221-42f4-a6ef-917b96b5f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_name_features = pd.read_csv(r\"project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "add_letter_to_cols(book_name_features, \"n\")\n",
    "\n",
    "book_desc_features = pd.read_csv(r\"project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "add_letter_to_cols(book_desc_features, \"d\")\n",
    "\n",
    "book_auth_features = pd.read_csv(r\"project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "add_letter_to_cols(book_auth_features, \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5993b31-f1f3-4671-b750-a7a1263a8296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>n4</th>\n",
       "      <th>n5</th>\n",
       "      <th>n6</th>\n",
       "      <th>n7</th>\n",
       "      <th>n8</th>\n",
       "      <th>n9</th>\n",
       "      <th>...</th>\n",
       "      <th>d91</th>\n",
       "      <th>d92</th>\n",
       "      <th>d93</th>\n",
       "      <th>d94</th>\n",
       "      <th>d95</th>\n",
       "      <th>d96</th>\n",
       "      <th>d97</th>\n",
       "      <th>d98</th>\n",
       "      <th>d99</th>\n",
       "      <th>rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052262</td>\n",
       "      <td>-0.263308</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.128574</td>\n",
       "      <td>-0.161565</td>\n",
       "      <td>-0.127520</td>\n",
       "      <td>0.249588</td>\n",
       "      <td>0.037621</td>\n",
       "      <td>-0.074043</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096503</td>\n",
       "      <td>0.894538</td>\n",
       "      <td>-0.386222</td>\n",
       "      <td>1.000658</td>\n",
       "      <td>1.094646</td>\n",
       "      <td>-0.897948</td>\n",
       "      <td>0.256250</td>\n",
       "      <td>-0.743381</td>\n",
       "      <td>-0.046537</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.129112</td>\n",
       "      <td>0.021312</td>\n",
       "      <td>0.159166</td>\n",
       "      <td>-0.072448</td>\n",
       "      <td>0.036028</td>\n",
       "      <td>-0.093721</td>\n",
       "      <td>0.129199</td>\n",
       "      <td>0.069736</td>\n",
       "      <td>-0.253263</td>\n",
       "      <td>-0.066424</td>\n",
       "      <td>...</td>\n",
       "      <td>2.018345</td>\n",
       "      <td>-0.515164</td>\n",
       "      <td>0.510041</td>\n",
       "      <td>1.042953</td>\n",
       "      <td>0.034085</td>\n",
       "      <td>0.397630</td>\n",
       "      <td>0.180119</td>\n",
       "      <td>-0.133072</td>\n",
       "      <td>1.251777</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.170058</td>\n",
       "      <td>0.052351</td>\n",
       "      <td>-0.013406</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>0.083173</td>\n",
       "      <td>-0.161439</td>\n",
       "      <td>0.048635</td>\n",
       "      <td>0.089419</td>\n",
       "      <td>-0.072266</td>\n",
       "      <td>-0.063164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043291</td>\n",
       "      <td>0.166269</td>\n",
       "      <td>0.443516</td>\n",
       "      <td>0.360877</td>\n",
       "      <td>0.637700</td>\n",
       "      <td>-0.399422</td>\n",
       "      <td>-0.217829</td>\n",
       "      <td>0.095041</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250849</td>\n",
       "      <td>0.021555</td>\n",
       "      <td>0.091047</td>\n",
       "      <td>-0.041589</td>\n",
       "      <td>-0.040949</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>0.415056</td>\n",
       "      <td>0.027029</td>\n",
       "      <td>-0.172413</td>\n",
       "      <td>-0.135485</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.064901</td>\n",
       "      <td>0.956356</td>\n",
       "      <td>0.537667</td>\n",
       "      <td>-1.156633</td>\n",
       "      <td>1.138308</td>\n",
       "      <td>0.287945</td>\n",
       "      <td>0.809811</td>\n",
       "      <td>-1.180691</td>\n",
       "      <td>-0.075178</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.041681</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>-0.051164</td>\n",
       "      <td>-0.076813</td>\n",
       "      <td>0.096855</td>\n",
       "      <td>-0.215943</td>\n",
       "      <td>0.152729</td>\n",
       "      <td>0.267636</td>\n",
       "      <td>-0.079954</td>\n",
       "      <td>-0.065560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.730932</td>\n",
       "      <td>-0.893566</td>\n",
       "      <td>0.982820</td>\n",
       "      <td>0.190981</td>\n",
       "      <td>0.605344</td>\n",
       "      <td>0.236092</td>\n",
       "      <td>0.653281</td>\n",
       "      <td>-0.581590</td>\n",
       "      <td>-0.850868</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>-0.129420</td>\n",
       "      <td>0.130302</td>\n",
       "      <td>-0.037361</td>\n",
       "      <td>-0.004281</td>\n",
       "      <td>-0.255112</td>\n",
       "      <td>...</td>\n",
       "      <td>2.021390</td>\n",
       "      <td>0.418629</td>\n",
       "      <td>-0.371224</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.869552</td>\n",
       "      <td>-3.437345</td>\n",
       "      <td>1.491958</td>\n",
       "      <td>2.093727</td>\n",
       "      <td>1.478695</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23059</th>\n",
       "      <td>-0.024484</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.015977</td>\n",
       "      <td>0.086630</td>\n",
       "      <td>0.082127</td>\n",
       "      <td>-0.174537</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>0.111608</td>\n",
       "      <td>-0.106961</td>\n",
       "      <td>-0.147956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234319</td>\n",
       "      <td>0.114523</td>\n",
       "      <td>0.223425</td>\n",
       "      <td>0.818674</td>\n",
       "      <td>0.719629</td>\n",
       "      <td>-1.334342</td>\n",
       "      <td>-1.144812</td>\n",
       "      <td>-0.270687</td>\n",
       "      <td>-1.546596</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23060</th>\n",
       "      <td>-0.099309</td>\n",
       "      <td>-0.046230</td>\n",
       "      <td>-0.033294</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>-0.055477</td>\n",
       "      <td>-0.033886</td>\n",
       "      <td>0.026869</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>-0.126636</td>\n",
       "      <td>0.127742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308627</td>\n",
       "      <td>-0.630947</td>\n",
       "      <td>-0.264485</td>\n",
       "      <td>0.316840</td>\n",
       "      <td>0.305589</td>\n",
       "      <td>-0.123598</td>\n",
       "      <td>-0.424452</td>\n",
       "      <td>-1.336598</td>\n",
       "      <td>0.163445</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23061</th>\n",
       "      <td>-0.038388</td>\n",
       "      <td>0.065679</td>\n",
       "      <td>-0.159324</td>\n",
       "      <td>-0.048682</td>\n",
       "      <td>0.054175</td>\n",
       "      <td>0.317751</td>\n",
       "      <td>0.065931</td>\n",
       "      <td>-0.126021</td>\n",
       "      <td>-0.105057</td>\n",
       "      <td>-0.147185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085357</td>\n",
       "      <td>-0.113327</td>\n",
       "      <td>1.173376</td>\n",
       "      <td>1.244604</td>\n",
       "      <td>1.042439</td>\n",
       "      <td>-0.130578</td>\n",
       "      <td>0.552256</td>\n",
       "      <td>1.143148</td>\n",
       "      <td>-0.685621</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23062</th>\n",
       "      <td>-0.051934</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>0.030417</td>\n",
       "      <td>0.044278</td>\n",
       "      <td>-0.031339</td>\n",
       "      <td>-0.020412</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.073363</td>\n",
       "      <td>-0.068429</td>\n",
       "      <td>-0.037205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284325</td>\n",
       "      <td>-0.456627</td>\n",
       "      <td>0.377431</td>\n",
       "      <td>0.335774</td>\n",
       "      <td>0.535361</td>\n",
       "      <td>-0.383517</td>\n",
       "      <td>0.215218</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>-0.013714</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23063 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             n0        n1        n2        n3        n4        n5        n6  \\\n",
       "0      0.052262 -0.263308  0.026872  0.128574 -0.161565 -0.127520  0.249588   \n",
       "1     -0.129112  0.021312  0.159166 -0.072448  0.036028 -0.093721  0.129199   \n",
       "2     -0.170058  0.052351 -0.013406  0.099001  0.083173 -0.161439  0.048635   \n",
       "3      0.250849  0.021555  0.091047 -0.041589 -0.040949  0.240260  0.415056   \n",
       "4     -0.041681  0.038051 -0.051164 -0.076813  0.096855 -0.215943  0.152729   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23058  0.007497  0.000220  0.019723 -0.003321  0.021097 -0.129420  0.130302   \n",
       "23059 -0.024484  0.000467 -0.015977  0.086630  0.082127 -0.174537  0.011694   \n",
       "23060 -0.099309 -0.046230 -0.033294  0.242591 -0.055477 -0.033886  0.026869   \n",
       "23061 -0.038388  0.065679 -0.159324 -0.048682  0.054175  0.317751  0.065931   \n",
       "23062 -0.051934 -0.005339  0.030417  0.044278 -0.031339 -0.020412  0.038031   \n",
       "\n",
       "             n7        n8        n9  ...       d91       d92       d93  \\\n",
       "0      0.037621 -0.074043  0.072854  ...  1.096503  0.894538 -0.386222   \n",
       "1      0.069736 -0.253263 -0.066424  ...  2.018345 -0.515164  0.510041   \n",
       "2      0.089419 -0.072266 -0.063164  ... -0.043291  0.166269  0.443516   \n",
       "3      0.027029 -0.172413 -0.135485  ... -1.064901  0.956356  0.537667   \n",
       "4      0.267636 -0.079954 -0.065560  ... -0.730932 -0.893566  0.982820   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "23058 -0.037361 -0.004281 -0.255112  ...  2.021390  0.418629 -0.371224   \n",
       "23059  0.111608 -0.106961 -0.147956  ...  0.234319  0.114523  0.223425   \n",
       "23060  0.038410 -0.126636  0.127742  ... -0.308627 -0.630947 -0.264485   \n",
       "23061 -0.126021 -0.105057 -0.147185  ... -0.085357 -0.113327  1.173376   \n",
       "23062  0.073363 -0.068429 -0.037205  ... -0.284325 -0.456627  0.377431   \n",
       "\n",
       "            d94       d95       d96       d97       d98       d99  \\\n",
       "0      1.000658  1.094646 -0.897948  0.256250 -0.743381 -0.046537   \n",
       "1      1.042953  0.034085  0.397630  0.180119 -0.133072  1.251777   \n",
       "2      0.360877  0.637700 -0.399422 -0.217829  0.095041  0.030425   \n",
       "3     -1.156633  1.138308  0.287945  0.809811 -1.180691 -0.075178   \n",
       "4      0.190981  0.605344  0.236092  0.653281 -0.581590 -0.850868   \n",
       "...         ...       ...       ...       ...       ...       ...   \n",
       "23058  0.595000  0.869552 -3.437345  1.491958  2.093727  1.478695   \n",
       "23059  0.818674  0.719629 -1.334342 -1.144812 -0.270687 -1.546596   \n",
       "23060  0.316840  0.305589 -0.123598 -0.424452 -1.336598  0.163445   \n",
       "23061  1.244604  1.042439 -0.130578  0.552256  1.143148 -0.685621   \n",
       "23062  0.335774  0.535361 -0.383517  0.215218  0.000406 -0.013714   \n",
       "\n",
       "       rating_label  \n",
       "0               4.0  \n",
       "1               4.0  \n",
       "2               4.0  \n",
       "3               4.0  \n",
       "4               3.0  \n",
       "...             ...  \n",
       "23058           4.0  \n",
       "23059           4.0  \n",
       "23060           4.0  \n",
       "23061           4.0  \n",
       "23062           4.0  \n",
       "\n",
       "[23063 rows x 221 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform label encoding for publishers, language\n",
    "label_encoder = LabelEncoder()\n",
    "#combined_df['Publisher'] = label_encoder.fit_transform(combined_df['Publisher'])\n",
    "#combined_df['Language'] = label_encoder.fit_transform(combined_df['Language'])\n",
    "\n",
    "combined_df = pd.concat([book_name_features, book_auth_features, book_desc_features, df['rating_label']], axis=1)\n",
    "# Separate the feature columns (X) and the target column (y)\n",
    "X = combined_df.drop('rating_label', axis=1)\n",
    "y = combined_df['rating_label']\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22fee49e-684a-4caf-894d-bda64bc1b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'n10', 'n11', 'n12', 'n13', 'n14', 'n15', 'n16', 'n17', 'n18', 'n19', 'n20', 'n21', 'n22', 'n23', 'n24', 'n25', 'n26', 'n27', 'n28', 'n29', 'n30', 'n31', 'n32', 'n33', 'n34', 'n35', 'n36', 'n37', 'n38', 'n39', 'n40', 'n41', 'n42', 'n43', 'n44', 'n45', 'n46', 'n47', 'n48', 'n49', 'n50', 'n51', 'n52', 'n53', 'n54', 'n55', 'n56', 'n57', 'n58', 'n59', 'n60', 'n61', 'n62', 'n63', 'n64', 'n65', 'n66', 'n67', 'n68', 'n69', 'n70', 'n71', 'n72', 'n73', 'n74', 'n75', 'n76', 'n77', 'n78', 'n79', 'n80', 'n81', 'n82', 'n83', 'n84', 'n85', 'n86', 'n87', 'n88', 'n89', 'n90', 'n91', 'n92', 'n93', 'n94', 'n95', 'n96', 'n97', 'n98', 'n99', 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a16', 'a17', 'a18', 'a19', 'd0', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd10', 'd11', 'd12', 'd13', 'd14', 'd15', 'd16', 'd17', 'd18', 'd19', 'd20', 'd21', 'd22', 'd23', 'd24', 'd25', 'd26', 'd27', 'd28', 'd29', 'd30', 'd31', 'd32', 'd33', 'd34', 'd35', 'd36', 'd37', 'd38', 'd39', 'd40', 'd41', 'd42', 'd43', 'd44', 'd45', 'd46', 'd47', 'd48', 'd49', 'd50', 'd51', 'd52', 'd53', 'd54', 'd55', 'd56', 'd57', 'd58', 'd59', 'd60', 'd61', 'd62', 'd63', 'd64', 'd65', 'd66', 'd67', 'd68', 'd69', 'd70', 'd71', 'd72', 'd73', 'd74', 'd75', 'd76', 'd77', 'd78', 'd79', 'd80', 'd81', 'd82', 'd83', 'd84', 'd85', 'd86', 'd87', 'd88', 'd89', 'd90', 'd91', 'd92', 'd93', 'd94', 'd95', 'd96', 'd97', 'd98', 'd99']\n",
      "Selected Features and Mutual Information Scores (in descending order):\n",
      "d65: 0.010223859523050383\n",
      "d90: 0.00958257710406607\n",
      "n17: 0.009273966985221316\n",
      "d39: 0.008949736074264303\n",
      "d16: 0.008643422881304819\n",
      "n66: 0.008385187518290538\n",
      "d79: 0.008044590756619563\n",
      "d87: 0.007974182677075392\n",
      "n38: 0.007939756508312579\n",
      "n31: 0.007866821045955152\n",
      "d85: 0.007782380863522453\n",
      "d93: 0.007497802319136548\n",
      "d61: 0.007306256125637178\n",
      "n85: 0.007303046315171535\n",
      "n76: 0.007141734558757884\n",
      "n53: 0.006982825984360508\n",
      "a19: 0.006828593886891499\n",
      "d12: 0.006802915267055898\n",
      "d32: 0.0067621838227405195\n",
      "n93: 0.006698209154423873\n",
      "d81: 0.0064193320865366665\n",
      "a14: 0.006403382687394821\n",
      "n57: 0.006384371805293387\n",
      "d8: 0.00635085427520532\n",
      "d69: 0.006072260497186344\n",
      "d15: 0.006050831902860709\n",
      "d41: 0.006036806477739631\n",
      "n77: 0.005928444484437634\n",
      "n7: 0.005925027270829553\n",
      "d75: 0.005870335080740308\n",
      "n4: 0.00547895009799948\n",
      "d47: 0.005349911180509981\n",
      "d96: 0.005317433155582085\n",
      "d53: 0.005119086576910625\n",
      "d38: 0.0050034636426623535\n",
      "n16: 0.004992632401961128\n",
      "d34: 0.004933877379465601\n",
      "n37: 0.004890380203901534\n",
      "d46: 0.004769820124252533\n",
      "n59: 0.004768991344109352\n",
      "n44: 0.004764550933738176\n",
      "a1: 0.00474892667876059\n",
      "d18: 0.004711364820518593\n",
      "a9: 0.004685996621530908\n",
      "n22: 0.004669175737043396\n",
      "n61: 0.004636720380267745\n",
      "d52: 0.0046268019580402164\n",
      "d4: 0.004526170993319534\n",
      "n18: 0.004520438056131226\n",
      "n8: 0.004515481518539088\n",
      "d73: 0.004488881717013005\n",
      "n10: 0.004411857601436031\n",
      "n79: 0.004410942071137569\n",
      "d77: 0.004407984916538821\n",
      "d67: 0.004387150870099887\n",
      "d49: 0.00434074946946561\n",
      "n96: 0.004338344448815645\n",
      "d71: 0.004302734057666013\n",
      "n82: 0.004274261798091761\n",
      "n52: 0.004237304201588188\n",
      "n74: 0.0042126437416345475\n",
      "n20: 0.004070079760759127\n",
      "d5: 0.004057129052202457\n",
      "a11: 0.004019262063124529\n",
      "d29: 0.00399847983933288\n",
      "d63: 0.003892701971727419\n",
      "d62: 0.0038916396973274203\n",
      "n48: 0.0038542629151991914\n",
      "n71: 0.003845997838385129\n",
      "d95: 0.0038184853910416816\n",
      "n30: 0.003699999371983065\n",
      "n84: 0.0036808492601649867\n",
      "n89: 0.0036199480249825555\n",
      "d55: 0.003613206212435216\n",
      "n78: 0.003586746370789262\n",
      "n36: 0.003586253794612304\n",
      "n83: 0.0035491415514155022\n",
      "d36: 0.0034597140637566692\n",
      "n51: 0.003317365543265449\n",
      "n42: 0.003249536722130353\n",
      "a6: 0.0032453694803151745\n",
      "a4: 0.0032349121845867135\n",
      "n95: 0.003091301976281713\n",
      "d40: 0.0030910036421420983\n",
      "d11: 0.00306115002891727\n",
      "d3: 0.0030366751055792562\n",
      "n21: 0.002981453791345734\n",
      "d45: 0.0029099054958523496\n",
      "n12: 0.0028685756961062125\n",
      "a7: 0.0028519353229583544\n",
      "d44: 0.002827836262879746\n",
      "n32: 0.0028116260527286663\n",
      "n69: 0.002709609964870019\n",
      "d99: 0.0026775182257654517\n",
      "d19: 0.0026635881479561974\n",
      "d64: 0.002654109686061945\n",
      "d92: 0.002579764314448285\n",
      "d84: 0.0025159545699009467\n",
      "d76: 0.002402434038786927\n",
      "d70: 0.0023301703301725762\n",
      "a3: 0.002304151183266212\n",
      "a17: 0.002298812214972079\n",
      "a2: 0.0022574185902082267\n",
      "d13: 0.0022290397560178477\n",
      "n80: 0.0021839123028997154\n",
      "n75: 0.0021697216477754022\n",
      "n70: 0.0021092884408462353\n",
      "n90: 0.0020649852939027546\n",
      "d10: 0.0020628827434534536\n",
      "d30: 0.0020592551116909164\n",
      "n25: 0.0020197361023091\n",
      "a0: 0.0020184938374556705\n",
      "n72: 0.0020183805269264887\n",
      "n60: 0.0019582235937598558\n",
      "d7: 0.0019443784030965805\n",
      "a10: 0.0019394528516993859\n",
      "d68: 0.001930195199074669\n",
      "n29: 0.0019004736027428137\n",
      "d86: 0.0018505171628651063\n",
      "n9: 0.001786115456657189\n",
      "d88: 0.001779437082534585\n",
      "n65: 0.0017130061431804844\n",
      "d83: 0.0017117389007812456\n",
      "n19: 0.0016662083265974736\n",
      "n81: 0.001640478541530932\n",
      "d14: 0.0016399034254528377\n",
      "n45: 0.0014795114617012217\n",
      "d80: 0.0013929372538377116\n",
      "a15: 0.001340589826471117\n",
      "n62: 0.0012904344631254894\n",
      "d51: 0.001273247367670427\n",
      "n2: 0.0012425418234445207\n",
      "d42: 0.0012384776696690025\n",
      "n43: 0.0012365922110375571\n",
      "d50: 0.0012047717426992843\n",
      "d24: 0.0012016625026842753\n",
      "n86: 0.0011848662085194306\n",
      "d59: 0.0011318347248459038\n",
      "a18: 0.0011132315704194262\n",
      "d22: 0.00110239591207284\n",
      "n49: 0.001101323754851613\n",
      "n6: 0.00109187240916242\n",
      "n91: 0.001023123673227877\n",
      "n5: 0.0009537689377860925\n",
      "d35: 0.0008970833047674542\n",
      "d28: 0.0008299095976365134\n",
      "a8: 0.0008110581690765617\n",
      "d48: 0.0008038669239684992\n",
      "n13: 0.0007850158079729663\n",
      "a5: 0.0007287174896579707\n",
      "d60: 0.0006758566082687434\n",
      "n88: 0.0005559457917079236\n",
      "a13: 0.0005403464554252224\n",
      "d1: 0.0004922085219130068\n",
      "d33: 0.00047353852592624257\n",
      "n41: 0.00043458266568330295\n",
      "n27: 0.0003985652526983241\n",
      "d94: 0.00038710471238712074\n",
      "d78: 0.0003536908732573174\n",
      "n11: 0.000350864714283583\n",
      "n54: 0.0002891934381725747\n",
      "n35: 0.00027764050750778146\n",
      "d89: 0.00015771188236879397\n",
      "d25: 0.0001327834226267921\n",
      "n99: 0.00011809858017985952\n",
      "d23: 0.00011532462193364346\n",
      "d66: 1.1935045694855262e-05\n",
      "d27: 4.09915534804739e-06\n",
      "n0: 0.0\n",
      "n1: 0.0\n",
      "n3: 0.0\n",
      "n14: 0.0\n",
      "n15: 0.0\n",
      "n23: 0.0\n",
      "n24: 0.0\n",
      "n26: 0.0\n",
      "n28: 0.0\n",
      "n33: 0.0\n",
      "n34: 0.0\n",
      "n39: 0.0\n",
      "n40: 0.0\n",
      "n46: 0.0\n",
      "n47: 0.0\n",
      "n50: 0.0\n",
      "n55: 0.0\n",
      "n56: 0.0\n",
      "n58: 0.0\n",
      "n63: 0.0\n",
      "n64: 0.0\n",
      "n67: 0.0\n",
      "n68: 0.0\n",
      "n73: 0.0\n",
      "n87: 0.0\n",
      "n92: 0.0\n",
      "n94: 0.0\n",
      "n97: 0.0\n",
      "n98: 0.0\n",
      "a12: 0.0\n",
      "a16: 0.0\n",
      "d0: 0.0\n",
      "d2: 0.0\n",
      "d6: 0.0\n",
      "d9: 0.0\n",
      "d17: 0.0\n",
      "d20: 0.0\n",
      "d21: 0.0\n",
      "d26: 0.0\n",
      "d31: 0.0\n",
      "d37: 0.0\n",
      "d43: 0.0\n",
      "d54: 0.0\n",
      "d56: 0.0\n",
      "d57: 0.0\n",
      "d58: 0.0\n",
      "d72: 0.0\n",
      "d74: 0.0\n",
      "d82: 0.0\n",
      "d91: 0.0\n",
      "d97: 0.0\n",
      "d98: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset into a pandas DataFrame\n",
    "\n",
    "# Select the continuous features you want to discretize\n",
    "continuous_features = list(combined_df.drop('rating_label', axis=1).columns)\n",
    "print(continuous_features)\n",
    "\n",
    "# Discretize the continuous features using equal width binning\n",
    "n_bins = 5  # Number of bins\n",
    "discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "discretized_data = discretizer.fit_transform(combined_df[continuous_features])\n",
    "\n",
    "# Create a new DataFrame with discretized features\n",
    "df_discretized = pd.DataFrame(discretized_data, columns=continuous_features)\n",
    "\n",
    "# Perform feature selection using mutual information\n",
    "target_variable = 'rating_label'  # Your target variable\n",
    "X = df_discretized  # Features\n",
    "y = combined_df[target_variable]  # Target variable\n",
    "\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "selected_features = selector.fit_transform(X, y)\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "selected_feature_names = [X.columns[idx] for idx in selected_feature_indices]\n",
    "selected_feature_scores = selector.scores_[selected_feature_indices]\n",
    "\n",
    "# Sort features by score in descending order\n",
    "sorted_features = sorted(zip(selected_feature_names, selected_feature_scores),\n",
    "                         key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the selected feature names and their mutual information scores in order\n",
    "print(\"Selected Features and Mutual Information Scores (in descending order):\")\n",
    "for feature, score in sorted_features:\n",
    "    print(f\"{feature}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04aeed94-5181-43bb-b6ce-5513be8c2190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score for d-features: 0.0028322501282761745\n",
      "Average score for n-features: 0.002405192864826591\n",
      "Average score for a-features: 0.002568532555710723\n"
     ]
    }
   ],
   "source": [
    "# Calculate averages for each letter-group\n",
    "averages = {}\n",
    "for feature, score in sorted_features:\n",
    "    letter_group = feature[0]  # Get the first character of the feature name\n",
    "    if letter_group not in averages:\n",
    "        averages[letter_group] = []\n",
    "    averages[letter_group].append(score)\n",
    "\n",
    "# Compute the average for each letter-group\n",
    "for letter_group, scores in averages.items():\n",
    "    average_score = sum(scores) / len(scores)\n",
    "    print(f\"Average score for {letter_group}-features: {average_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cfdf0-a2bb-44a9-ad79-388e0f584e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
