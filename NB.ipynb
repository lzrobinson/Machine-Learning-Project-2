{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7498da8a-5cf1-4cfd-8886-a43c1adca46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22bec017-fa56-4728-aa5c-e610e1dbdc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnLanguage(file, doc2vec):\n",
    "    \n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    X = pd.read_csv(doc2vec, index_col = False, delimiter = ',', header = None)\n",
    "    y = data[\"Language\"]\n",
    "    \n",
    "    y = pd.Series(y)\n",
    "    # Assuming you have a feature matrix `X` and a target variable `y`\n",
    "    # X should contain other features like doc2vec and word frequency counts\n",
    "    # y should contain the language labels (with missing values)\n",
    "\n",
    "    # Split the dataset into instances with and without missing language values\n",
    "    X_with_language = X[~y.isnull()]\n",
    "    y_with_language = y[~y.isnull()]\n",
    "    X_missing_language = X[y.isnull()]\n",
    "\n",
    "    # Split the dataset with language into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_with_language, y_with_language, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a Random Forest classifier on the instances with language\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the missing language values using the trained model\n",
    "    imputed_language = rf.predict(X_missing_language)\n",
    "\n",
    "    # Merge the imputed language values with the original dataset\n",
    "    y[y.isnull()] = imputed_language\n",
    "\n",
    "    # Now you can proceed with your machine learning algorithm using the complete dataset\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf7f0c0a-ca97-4c83-9ad5-c1a86f8cefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts a categorical feature into nominal, while maintaing categorical properties\n",
    "def numericise_categorical_data(df, feature):\n",
    "    df[feature] = df[feature].astype(str)\n",
    "    df[feature] = df[feature].astype('category')\n",
    "    df_encoded = pd.get_dummies(df, columns=[feature])\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    df[feature] = encoder.fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d7962de-ff96-4818-8bc2-4d38f480a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_df = pd.read_csv('project_data_files/book_rating_train.csv')\n",
    "test_df = pd.read_csv('project_data_files/book_rating_test.csv')\n",
    "\n",
    "# Add the predicted languages to each entry\n",
    "lang = learnLanguage('project_data_files/book_rating_train.csv', \"project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\")\n",
    "train_df['Language'] = lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "355d749e-8d04-4c09-9962-aa86f93e97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_letter_to_cols(df, letter):\n",
    "    for column in df.columns:\n",
    "        new_name = letter + str(column)\n",
    "        df.rename(columns={column: new_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "317f2ac3-19e2-4855-97ff-4efcfc6cd671",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('Name', axis=1)\n",
    "train_df = train_df.drop('Description', axis=1)\n",
    "train_df = train_df.drop('Authors', axis=1)\n",
    "\n",
    "\n",
    "# Remove the title, description and replace with doc2vec\n",
    "book_name_features = pd.read_csv(r\"project_data_files/book_text_features_doc2vec/train_name_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "add_letter_to_cols(book_name_features, \"n\")\n",
    "\n",
    "book_desc_features = pd.read_csv(r\"project_data_files/book_text_features_doc2vec/train_desc_doc2vec100.csv\", index_col = False, delimiter = ',', header=None)\n",
    "add_letter_to_cols(book_desc_features, \"d\")\n",
    "\n",
    "book_auth_features = pd.read_csv(r\"project_data_files/book_text_features_doc2vec/train_authors_doc2vec20.csv\", index_col = False, delimiter = ',', header=None)\n",
    "add_letter_to_cols(book_auth_features, \"a\")\n",
    "\n",
    "combined_df = pd.concat([train_df, book_name_features, book_desc_features, book_auth_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ee8e43d-1146-4361-8eba-96348df5c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform label encoding for publishers, language\n",
    "#combined_df['Publisher'] = label_encoder.fit_transform(combined_df['Publisher'])\n",
    "#combined_df['Language'] = label_encoder.fit_transform(combined_df['Language'])\n",
    "numericise_categorical_data(combined_df, 'Publisher')\n",
    "numericise_categorical_data(combined_df, 'Language')\n",
    "\n",
    "#combined_df = pd.concat([book_name_features, book_desc_features, train_df['rating_label']], axis=1)\n",
    "# Separate the feature columns (X) and the target column (y)\n",
    "X = combined_df.copy()\n",
    "X = X.drop('rating_label', axis=1)\n",
    "y = combined_df['rating_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6933c2a8-b695-4764-867e-3e56c581e742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>PublishMonth</th>\n",
       "      <th>PublishDay</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Language</th>\n",
       "      <th>pagesNumber</th>\n",
       "      <th>n0</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>n3</th>\n",
       "      <th>...</th>\n",
       "      <th>a10</th>\n",
       "      <th>a11</th>\n",
       "      <th>a12</th>\n",
       "      <th>a13</th>\n",
       "      <th>a14</th>\n",
       "      <th>a15</th>\n",
       "      <th>a16</th>\n",
       "      <th>a17</th>\n",
       "      <th>a18</th>\n",
       "      <th>a19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3664</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>0.052262</td>\n",
       "      <td>-0.263308</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>0.128574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329671</td>\n",
       "      <td>0.343979</td>\n",
       "      <td>0.018261</td>\n",
       "      <td>0.115687</td>\n",
       "      <td>-0.111172</td>\n",
       "      <td>0.068306</td>\n",
       "      <td>0.158065</td>\n",
       "      <td>0.053510</td>\n",
       "      <td>-0.136804</td>\n",
       "      <td>-0.084448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1108</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.129112</td>\n",
       "      <td>0.021312</td>\n",
       "      <td>0.159166</td>\n",
       "      <td>-0.072448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400349</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.349188</td>\n",
       "      <td>0.020555</td>\n",
       "      <td>0.281087</td>\n",
       "      <td>0.231422</td>\n",
       "      <td>0.129853</td>\n",
       "      <td>-0.213233</td>\n",
       "      <td>-0.081253</td>\n",
       "      <td>-0.204687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>810</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.170058</td>\n",
       "      <td>0.052351</td>\n",
       "      <td>-0.013406</td>\n",
       "      <td>0.099001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225617</td>\n",
       "      <td>-0.004355</td>\n",
       "      <td>0.173353</td>\n",
       "      <td>0.087015</td>\n",
       "      <td>0.106534</td>\n",
       "      <td>0.040950</td>\n",
       "      <td>0.209152</td>\n",
       "      <td>-0.215313</td>\n",
       "      <td>-0.177547</td>\n",
       "      <td>-0.178094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>0.250849</td>\n",
       "      <td>0.021555</td>\n",
       "      <td>0.091047</td>\n",
       "      <td>-0.041589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133304</td>\n",
       "      <td>-0.069995</td>\n",
       "      <td>0.206028</td>\n",
       "      <td>0.089625</td>\n",
       "      <td>0.157605</td>\n",
       "      <td>0.131767</td>\n",
       "      <td>0.244849</td>\n",
       "      <td>-0.321698</td>\n",
       "      <td>-0.198365</td>\n",
       "      <td>-0.208098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2005</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2820</td>\n",
       "      <td>1</td>\n",
       "      <td>352</td>\n",
       "      <td>-0.041681</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>-0.051164</td>\n",
       "      <td>-0.076813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224210</td>\n",
       "      <td>0.049880</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.062291</td>\n",
       "      <td>-0.030742</td>\n",
       "      <td>0.130882</td>\n",
       "      <td>0.295086</td>\n",
       "      <td>-0.061550</td>\n",
       "      <td>-0.244197</td>\n",
       "      <td>-0.272161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23058</th>\n",
       "      <td>1997</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.019723</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352087</td>\n",
       "      <td>-0.003458</td>\n",
       "      <td>0.148963</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.207720</td>\n",
       "      <td>0.070757</td>\n",
       "      <td>0.372283</td>\n",
       "      <td>-0.202811</td>\n",
       "      <td>-0.110761</td>\n",
       "      <td>-0.332954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23059</th>\n",
       "      <td>2005</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1603</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.024484</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>-0.015977</td>\n",
       "      <td>0.086630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036516</td>\n",
       "      <td>-0.076491</td>\n",
       "      <td>0.343184</td>\n",
       "      <td>-0.041826</td>\n",
       "      <td>0.242226</td>\n",
       "      <td>0.140699</td>\n",
       "      <td>0.104105</td>\n",
       "      <td>-0.140699</td>\n",
       "      <td>-0.004226</td>\n",
       "      <td>-0.291587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23060</th>\n",
       "      <td>1989</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3220</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>-0.099309</td>\n",
       "      <td>-0.046230</td>\n",
       "      <td>-0.033294</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359741</td>\n",
       "      <td>-0.077176</td>\n",
       "      <td>0.297625</td>\n",
       "      <td>0.172478</td>\n",
       "      <td>0.149067</td>\n",
       "      <td>-0.003060</td>\n",
       "      <td>0.270723</td>\n",
       "      <td>-0.324030</td>\n",
       "      <td>-0.264965</td>\n",
       "      <td>-0.269051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23061</th>\n",
       "      <td>1998</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>2550</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>-0.038388</td>\n",
       "      <td>0.065679</td>\n",
       "      <td>-0.159324</td>\n",
       "      <td>-0.048682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266749</td>\n",
       "      <td>-0.052155</td>\n",
       "      <td>0.195081</td>\n",
       "      <td>0.126226</td>\n",
       "      <td>0.097224</td>\n",
       "      <td>0.052020</td>\n",
       "      <td>0.191786</td>\n",
       "      <td>-0.234276</td>\n",
       "      <td>-0.214879</td>\n",
       "      <td>-0.224103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23062</th>\n",
       "      <td>2002</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3023</td>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "      <td>-0.051934</td>\n",
       "      <td>-0.005339</td>\n",
       "      <td>0.030417</td>\n",
       "      <td>0.044278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164892</td>\n",
       "      <td>0.092619</td>\n",
       "      <td>0.134980</td>\n",
       "      <td>0.359662</td>\n",
       "      <td>0.033413</td>\n",
       "      <td>0.195595</td>\n",
       "      <td>0.286306</td>\n",
       "      <td>-0.131477</td>\n",
       "      <td>0.047083</td>\n",
       "      <td>-0.167879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23063 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PublishYear  PublishMonth  PublishDay  Publisher  Language  \\\n",
       "0             2005             6           1       3664         1   \n",
       "1             1991            10           1       1108         1   \n",
       "2             2005             3          31        810         1   \n",
       "3             2004             9           1        480         1   \n",
       "4             2005             7           7       2820         1   \n",
       "...            ...           ...         ...        ...       ...   \n",
       "23058         1997             8           1          7         1   \n",
       "23059         2005             6           1       1603         1   \n",
       "23060         1989             2          15       3220         1   \n",
       "23061         1998             4          21       2550         1   \n",
       "23062         2002             7           8       3023         1   \n",
       "\n",
       "       pagesNumber        n0        n1        n2        n3  ...       a10  \\\n",
       "0               48  0.052262 -0.263308  0.026872  0.128574  ...  0.329671   \n",
       "1              364 -0.129112  0.021312  0.159166 -0.072448  ...  0.400349   \n",
       "2               32 -0.170058  0.052351 -0.013406  0.099001  ...  0.225617   \n",
       "3              293  0.250849  0.021555  0.091047 -0.041589  ...  0.133304   \n",
       "4              352 -0.041681  0.038051 -0.051164 -0.076813  ...  0.224210   \n",
       "...            ...       ...       ...       ...       ...  ...       ...   \n",
       "23058          120  0.007497  0.000220  0.019723 -0.003321  ...  0.352087   \n",
       "23059           32 -0.024484  0.000467 -0.015977  0.086630  ...  0.036516   \n",
       "23060          132 -0.099309 -0.046230 -0.033294  0.242591  ...  0.359741   \n",
       "23061          136 -0.038388  0.065679 -0.159324 -0.048682  ...  0.266749   \n",
       "23062          192 -0.051934 -0.005339  0.030417  0.044278  ...  0.164892   \n",
       "\n",
       "            a11       a12       a13       a14       a15       a16       a17  \\\n",
       "0      0.343979  0.018261  0.115687 -0.111172  0.068306  0.158065  0.053510   \n",
       "1      0.065201  0.349188  0.020555  0.281087  0.231422  0.129853 -0.213233   \n",
       "2     -0.004355  0.173353  0.087015  0.106534  0.040950  0.209152 -0.215313   \n",
       "3     -0.069995  0.206028  0.089625  0.157605  0.131767  0.244849 -0.321698   \n",
       "4      0.049880  0.003623  0.062291 -0.030742  0.130882  0.295086 -0.061550   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23058 -0.003458  0.148963  0.063023  0.207720  0.070757  0.372283 -0.202811   \n",
       "23059 -0.076491  0.343184 -0.041826  0.242226  0.140699  0.104105 -0.140699   \n",
       "23060 -0.077176  0.297625  0.172478  0.149067 -0.003060  0.270723 -0.324030   \n",
       "23061 -0.052155  0.195081  0.126226  0.097224  0.052020  0.191786 -0.234276   \n",
       "23062  0.092619  0.134980  0.359662  0.033413  0.195595  0.286306 -0.131477   \n",
       "\n",
       "            a18       a19  \n",
       "0     -0.136804 -0.084448  \n",
       "1     -0.081253 -0.204687  \n",
       "2     -0.177547 -0.178094  \n",
       "3     -0.198365 -0.208098  \n",
       "4     -0.244197 -0.272161  \n",
       "...         ...       ...  \n",
       "23058 -0.110761 -0.332954  \n",
       "23059 -0.004226 -0.291587  \n",
       "23060 -0.264965 -0.269051  \n",
       "23061 -0.214879 -0.224103  \n",
       "23062  0.047083 -0.167879  \n",
       "\n",
       "[23063 rows x 226 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f73ab1fe-64a6-478c-baa1-5cb0fa600e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7045306741816605\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>index</th>\n",
       "      <th>rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>247</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12038</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1580</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3128</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>20531</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4608</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12586</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7683</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>4.0</td>\n",
       "      <td>12912</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9134</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4612</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7893</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  index  rating_label\n",
       "0     4.0    247           4.0\n",
       "1     4.0  12038           3.0\n",
       "2     4.0   1580           4.0\n",
       "3     3.0   3128           4.0\n",
       "4     4.0  20531           4.0\n",
       "...   ...    ...           ...\n",
       "4608  4.0  12586           3.0\n",
       "4609  4.0   7683           4.0\n",
       "4610  4.0  12912           4.0\n",
       "4611  4.0   9134           4.0\n",
       "4612  4.0   7893           4.0\n",
       "\n",
       "[4613 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL 1: Discretise all data, then use Categorical Naive Bayes\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select categorical and continuous features\n",
    "categorical_features = ['Publisher', 'Language']  # Add your categorical feature column names here\n",
    "continuous_features = ['con_feature1', 'con_feature2']  # Add your continuous feature column names here\n",
    "\n",
    "# Create and train the Categorical Naive Bayes classifier\n",
    "nb_classifier = CategoricalNB()\n",
    "nb_classifier.fit(X_train[categorical_features], y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X_test[categorical_features])\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "combined = pd.concat([pd.Series(y_pred), y_test.reset_index()], axis=1)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "90f0b3da-4963-4382-814c-fd6843206e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6516366789507912\n",
      "4.0    3879\n",
      "3.0     418\n",
      "5.0     316\n",
      "dtype: int64\n",
      "4.0    3281\n",
      "3.0    1136\n",
      "5.0     196\n",
      "Name: rating_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load your dataset into a pandas DataFrame\n",
    "\n",
    "# Select the continuous features you want to discretize (everything except for language, publisher and rating_label features)\n",
    "continuous_features = [col for col in X.columns if not col.startswith('Language') or not col.startswith('Publisher') or not col.startswith('rating_label')]\n",
    "\n",
    "# Discretize the continuous features using equal-weight binning\n",
    "discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "X_train_continuous = X_train[continuous_features]\n",
    "X_test_continuous = X_test[continuous_features]\n",
    "X_train_continuous_discretized = discretizer.fit_transform(X_train_continuous)\n",
    "X_test_continuous_discretized = discretizer.transform(X_test_continuous)\n",
    "\n",
    "# Replace the original continuous features with the discretized values\n",
    "X_train_discretized = X_train.copy()\n",
    "X_test_discretized = X_test.copy()\n",
    "X_train_discretized[continuous_features] = X_train_continuous_discretized\n",
    "X_test_discretized[continuous_features] = X_test_continuous_discretized\n",
    "\n",
    "# Concatenate the categorical and discretized continuous features\n",
    "X_train_combined = pd.concat([X_train_discretized[categorical_features], X_train_discretized[continuous_features]], axis=1)\n",
    "X_test_combined = pd.concat([X_test_discretized[categorical_features], X_test_discretized[continuous_features]], axis=1)\n",
    "\n",
    "# Create and train the Categorical Naive Bayes classifier\n",
    "nb_classifier = CategoricalNB()\n",
    "nb_classifier.fit(X_train_combined, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_classifier.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "combined = pd.concat([pd.Series(y_pred), y_test.reset_index()], axis=1)\n",
    "print(pd.Series(y_pred).value_counts())\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f57b2c-7d95-4eb1-92de-8f59e715bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CROSS VALIDATION, FEATURE SELECTION ON NB MODEL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
